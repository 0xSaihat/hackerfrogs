import requests
from bs4 import BeautifulSoup, Comment

def search_webpage(url, target_text):
    # Fetch the webpage
    response = requests.get(url)
    if response.status_code != 200:
        print("Failed to fetch:", url)
        return False
    
    # Parse the webpage content
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # Check for the target text in visible text
    if target_text in soup.get_text():
        return True
    
    # Check for the target text in comments
    for comment in soup.find_all(text=lambda text: isinstance(text, Comment)):
        if target_text in comment:
            return True
    
    # Check for the target text in script tags
    for script in soup.find_all('script'):
        if script.string and target_text in script.string:
            return True
    
    return False

def search_urls_in_file(file_path, target_text):
    try:
        with open(file_path, 'r') as file:
            for line in file:
                url = line.strip()
                if search_webpage(url, target_text):
                    print("Search term '{}' found in URL: {}".format(target_text, url))
    except FileNotFoundError:
        print("File not found:", file_path)

# Example usage:
file_path = 'urls.txt'  # Path to the text file containing URLs
target_text = 'pico'  # Search term
search_urls_in_file(file_path, target_text)
